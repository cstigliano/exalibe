# exalibe

## How does the Graphene think? - Graphene inspired Quantum Machine Learning

![Graphene layers](https://raw.githubusercontent.com/cstigliano/exalibe/master/images/grapheneLayers.jpg)

It all started with 1 and 0: the so called bit. And now? We are talking about qubit: an enhancement of the bit which can pass from a 1 or 0 state to a superposition that includes both 1 and 0 at the same time. As a result we have a super calculus capacity that opens to a new world of possibilities. And that’s only the very beginning.

What does all that mean? We still work with computers that use 0 and 1 in their calculus … so does it really have sense talking about qubit? Or is it just an approximation of something that doesn’t even exist?

Well, on one hand we can say that the qubit does exist as well as we can say the same about us! The quantum mechanics is at the base of the most powerful discovers that have allowed our society to be what actually is. On the other hand, it doesn’t matter how hard we try, if our computer works on 0 and 1, every machine learning algorithm called quantum will always perform as the classical model.

Said that, why should we limit our imagination by physics constraints? Someone once said “If you can dream it, you can do it!”.
We don’t have a quantum computer, yet. Maybe someone at Google can answer back “Yes, we do”, but it doesn’t matter right now. I want to focus on our real possibilities of the moment: all we have is a computer, a good internet connection and, why not, a little bit of recklessness.

### Let’s say we don’t care about the result, but the journey.

Nowadays, as far as I’m concerned, the most exciting point of machine learning is the attempt to replicate the neuron’s functions. Amazing! Don’t you think? The so called perceptron is a mathematical rappresentation of the behavior of a neuron that receives an input, works on it applying some kind of math and returns as a result an output. Until now, everything clear. This kind of rappresentation has let the most spectacular application of machine learning and artificial intelligence. But let me say one thing: the perceptron and the neuron don’t have anything in common! From a different point of view, we can consider the perceptron as the shadow of a neuron. More over the bit is the shadow of a qubit!

By bringing on this reasoning, we can’t explain the behavior of the neuron without some kind of quantum theory. At the same time we can’t understand quantum theory if we keep thinking in the classical way.
To open up our eyes, we just have to make a jump, the same way as quantum particles jump from a wave form to a matter form. Nobody knows how, that’s the point! But it happens! The foundamentals of quantum mechanics dwell on the well known assumption “If you think you understand quantum mechanics, you don’t understand quantum mechanics!”. 

Without digress to much into what has already been said in thousand of videos and lectures, what I want to bring to your attention is the characteristic of learning: experience.

Without experience there is no learning. The same way we learn from experience, even our machine learning models have to be trained on data to resolve problems. Otherwise, all we got is just an empty script.

That’s obvious. But at the same time critic. We can understand and resolve new problems only on the base of what we have experienced. What if the new problem needs a totally new approach? What if we train our model with data that can’t rappresent the new problem?
What I’m trying to say is that facing new problem with a new approach is the actual challenge of all we have learned about ML and AI. It seems that the dream of every man of science is to build ML algorithms that enhance AI that should teach us how to implement our ML models and so on. Someone could say that it is the eternal research of God: the omni-consciousness freed from experience.

I’m not going to say that’s impossible or pointless, because the reality always teachs that some kind of things are so impossible to happens that actually happens. I’m only saying that even the quantum supremacy, which should solve problems that require 100.000 years for the most powerful computer of our days, is an old approach to new problems. The point is: it doesn’t matter how fast or accurate the response could be if the question is not well formulated.

My purpose is to rethink starting from zero … maybe one … maybe both.

To do this a will ask the help of Graphene, trying to redesign the concept of thinking itself.

You can read my article on [Medium](https://medium.com/@claudiostigliano/how-does-the-graphene-think-ae41890c9ff5).



